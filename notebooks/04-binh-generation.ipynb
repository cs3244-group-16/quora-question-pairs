{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a1cd60f-88c0-4b68-b5c4-a0b6122b6346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import sentencepiece as spm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da21b639-5e71-4d16-8e05-5038ac8294ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45e30824-2caa-4b4e-b91d-f7b5faa7a14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = join('..', 'data', 'raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d185c50c-2966-4d0a-9691-b1f12d2b784d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>133273</td>\n",
       "      <td>213221</td>\n",
       "      <td>213222</td>\n",
       "      <td>How is the life of a math student? Could you d...</td>\n",
       "      <td>Which level of prepration is enough for the ex...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>402555</td>\n",
       "      <td>536040</td>\n",
       "      <td>536041</td>\n",
       "      <td>How do I control my horny emotions?</td>\n",
       "      <td>How do you control your horniness?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>360472</td>\n",
       "      <td>364011</td>\n",
       "      <td>490273</td>\n",
       "      <td>What causes stool color to change to yellow?</td>\n",
       "      <td>What can cause stool to come out as little balls?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150662</td>\n",
       "      <td>155721</td>\n",
       "      <td>7256</td>\n",
       "      <td>What can one do after MBBS?</td>\n",
       "      <td>What do i do after my MBBS ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>183004</td>\n",
       "      <td>279958</td>\n",
       "      <td>279959</td>\n",
       "      <td>Where can I find a power outlet for my laptop ...</td>\n",
       "      <td>Would a second airport in Sydney, Australia be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    qid1    qid2                                          question1  \\\n",
       "0  133273  213221  213222  How is the life of a math student? Could you d...   \n",
       "1  402555  536040  536041                How do I control my horny emotions?   \n",
       "2  360472  364011  490273       What causes stool color to change to yellow?   \n",
       "3  150662  155721    7256                        What can one do after MBBS?   \n",
       "4  183004  279958  279959  Where can I find a power outlet for my laptop ...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  Which level of prepration is enough for the ex...             0  \n",
       "1                 How do you control your horniness?             1  \n",
       "2  What can cause stool to come out as little balls?             0  \n",
       "3                       What do i do after my MBBS ?             1  \n",
       "4  Would a second airport in Sydney, Australia be...             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full_df = pd.read_csv(join(DATA_DIR, 'train.tsv'), sep='\\t')\n",
    "train_full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "000f257f-fc3e-49e7-a20f-83293b6ba2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_append_df = pd.read_csv(join(DATA_DIR, 'test.tsv'), sep='\\t')\n",
    "test_df = pd.read_csv(join(DATA_DIR, 'dev.tsv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d7692f8-4a51-4409-876d-3b3f3dc65309",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full_df = pd.concat([train_full_df, train_append_df])\n",
    "train_full_df = train_full_df[['question1', 'question2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0d5dbdd-7054-49be-84c1-3f49f103268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, dev_df = train_test_split(train_full_df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ed08f5e-f6d9-46cc-9161-69ac50b89e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/processed/train_samples.txt', 'w') as f:\n",
    "    for _, row in train_df.iterrows():\n",
    "        f.write(row['question1'] + '\\n')\n",
    "        f.write(row['question2'] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c86b63c-5b9e-4bcc-bf69-55e0051e1c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ../data/processed/train_samples.txt\n",
      "  input_format: \n",
      "  model_prefix: ../models/trained/spm-8k\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 8000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ‚Åá \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(183) LOG(INFO) Loading corpus: ../data/processed/train_samples.txt\n",
      "trainer_interface.cc(145) LOG(INFO) Loaded 1000000 lines\n",
      "trainer_interface.cc(122) LOG(WARNING) Too many sentences are loaded! (1358658), which may slow down training.\n",
      "trainer_interface.cc(124) LOG(WARNING) Consider using --input_sentence_size=<size> and --shuffle_input_sentence=true.\n",
      "trainer_interface.cc(127) LOG(WARNING) They allow to randomly sample <size> sentences from the entire corpus.\n",
      "trainer_interface.cc(407) LOG(INFO) Loaded all 1358658 sentences\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(537) LOG(INFO) all chars count=83036990\n",
      "trainer_interface.cc(548) LOG(INFO) Done: 99.9541% characters are covered.\n",
      "trainer_interface.cc(558) LOG(INFO) Alphabet size=83\n",
      "trainer_interface.cc(559) LOG(INFO) Final character coverage=0.999541\n",
      "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 1358658 sentences.\n",
      "unigram_model_trainer.cc(222) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(226) LOG(INFO) Extracting frequent sub strings... node_num=50018774\n",
      "unigram_model_trainer.cc(274) LOG(INFO) Initialized 331675 seed sentencepieces\n",
      "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 1358658\n",
      "trainer_interface.cc(608) LOG(INFO) Done! 325576\n",
      "unigram_model_trainer.cc(564) LOG(INFO) Using 325576 sentences for EM training\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=134807 obj=10.4521 num_tokens=773256 num_tokens/piece=5.73602\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=115934 obj=8.11043 num_tokens=775387 num_tokens/piece=6.68818\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=86946 obj=8.07192 num_tokens=803966 num_tokens/piece=9.24673\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=86906 obj=8.06628 num_tokens=804049 num_tokens/piece=9.25194\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=65179 obj=8.09348 num_tokens=849683 num_tokens/piece=13.0361\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=65178 obj=8.0857 num_tokens=849657 num_tokens/piece=13.0359\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=48882 obj=8.12983 num_tokens=900846 num_tokens/piece=18.429\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=48882 obj=8.1219 num_tokens=901183 num_tokens/piece=18.4359\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=36661 obj=8.18182 num_tokens=955208 num_tokens/piece=26.0552\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=36661 obj=8.17092 num_tokens=955139 num_tokens/piece=26.0533\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=27495 obj=8.25166 num_tokens=1010814 num_tokens/piece=36.7636\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=27495 obj=8.23696 num_tokens=1010710 num_tokens/piece=36.7598\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=20621 obj=8.34306 num_tokens=1068218 num_tokens/piece=51.8024\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=20621 obj=8.32433 num_tokens=1068171 num_tokens/piece=51.8002\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=15465 obj=8.45704 num_tokens=1128046 num_tokens/piece=72.9419\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=15465 obj=8.4331 num_tokens=1128015 num_tokens/piece=72.9399\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=11598 obj=8.59445 num_tokens=1189749 num_tokens/piece=102.582\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=11598 obj=8.56506 num_tokens=1189852 num_tokens/piece=102.591\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=8800 obj=8.75092 num_tokens=1248713 num_tokens/piece=141.899\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=8800 obj=8.71751 num_tokens=1248761 num_tokens/piece=141.905\n",
      "trainer_interface.cc(686) LOG(INFO) Saving model: ../models/trained/spm-8k.model\n",
      "trainer_interface.cc(698) LOG(INFO) Saving vocabs: ../models/trained/spm-8k.vocab\n"
     ]
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.train(\n",
    "    input='../data/processed/train_samples.txt', model_prefix='../models/trained/spm-8k', vocab_size=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca6ff63d-7687-4bde-83b7-c7c1c89c01f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor(model_file='../models/trained/spm-8k.model', add_bos=True, add_eos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ecfbe82-e32f-4990-aa8e-1421045f2e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4259, 9, 8, 5024, 539, 22, 2]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This is a sample sentence.\"\n",
    "sp.encode(text, out_type=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02f88b0c-8a0e-4f90-9676-7f2747156732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a sample sentence.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.decode([1, 4259, 9, 8, 5024, 539, 22, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9a4d16-e4ee-4dc7-b52d-ae9327615266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
