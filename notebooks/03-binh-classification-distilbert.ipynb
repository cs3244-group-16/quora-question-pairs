{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cee3ced7-ac73-471d-adf3-7773d66ca7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.functional as F\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "\n",
    "np.random.seed(42)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d7c29a4-12dc-43bf-8415-03fc9e35c0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = join('..', 'data', 'raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91367f04-7b47-47a0-8668-87ab7fcd0962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(join(DATA_DIR, 'train.csv'))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "093d3766-2ed0-46ad-8fd6-4ff840c7a4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.fillna(\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d535c66-3354-454e-990d-c31e04e68a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEP = '[SEP]'\n",
    "train_df['question1'] = train_df['question1'].str.lower()\n",
    "train_df['question2'] = train_df['question2'].str.lower()\n",
    "train_df['concat_qns'] = train_df['question1'] + ' ' + SEP + ' ' + train_df['question2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d48e498-8b8a-49c7-aec7-66103a3d1fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what is the step by step guide to invest in share market in india? [SEP] what is the step by step guide to invest in share market?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[0, 'concat_qns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "895cb383-6dc6-4827-b748-fbfe2a8b05fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', return_dict=False)\n",
    "\n",
    "class QuoraDataset(Dataset):\n",
    "    def __init__(self, X, y, tokenizer, max_len):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        qns = str(self.X.iloc[index]['concat_qns'])\n",
    "        encoded_qns = self.tokenizer.encode_plus(\n",
    "            qns,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=True,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "        )\n",
    "        ids = encoded_qns['input_ids']\n",
    "        mask = encoded_qns['attention_mask']\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'target': torch.tensor(self.y[index])\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "X = train_df[['concat_qns']]\n",
    "y = train_df['is_duplicate']\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "train_dataset = QuoraDataset(X_train[:256], y_train[:256], tokenizer, MAX_LEN)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_dataset = QuoraDataset(X_val[:256], y_val[:256], tokenizer, MAX_LEN)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataset = QuoraDataset(X_val, y_val, tokenizer, MAX_LEN)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69e0c87e-057f-4af6-889a-ee84db0c6a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilBertClass(torch.nn.Module):\n",
    "    def __init__(self, dropout=0.1):\n",
    "        super(DistilBertClass, self).__init__()\n",
    "        self.l1 = DistilBertModel.from_pretrained('distilbert-base-uncased', return_dict=False)\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.classifier = torch.nn.Linear(768, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        output = self.sigmoid(output)\n",
    "        return output\n",
    "\n",
    "def train(model, criterion, optimizer, scheduler=None, num_epochs=1):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "            ids = batch['ids'].to(device, dtype = torch.long)\n",
    "            mask = batch['mask'].to(device, dtype = torch.long)\n",
    "            labels = batch['target'].to(device, dtype = torch.float)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(ids, attention_mask=mask)\n",
    "            loss = criterion(outputs.view(-1), labels)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if scheduler: scheduler.step()\n",
    "        print(f\"Epoch {epoch+1}: loss = {total_loss:.2f}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # train set\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch in tqdm(train_loader):\n",
    "            ids = batch['ids'].to(device, dtype = torch.long)\n",
    "            mask = batch['mask'].to(device, dtype = torch.long)\n",
    "            labels = batch['target'].to(device, dtype = torch.float)\n",
    "\n",
    "            outputs = model(ids, attention_mask=mask)\n",
    "            predicted = (outputs > 0.5).float().view(-1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Train Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "        # validation set\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch in tqdm(val_loader):\n",
    "            ids = batch['ids'].to(device, dtype = torch.long)\n",
    "            mask = batch['mask'].to(device, dtype = torch.long)\n",
    "            labels = batch['target'].to(device, dtype = torch.float)\n",
    "\n",
    "            outputs = model(ids, attention_mask=mask)\n",
    "            predicted = (outputs > 0.5).float().view(-1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Validation Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d6a6492-db99-4dd9-9df5-867cf45f4d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                | 0/16 [00:00<?, ?it/s]/root/quora-question-pairs/venv/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_87980/4092967388.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'target': torch.tensor(self.y[index])\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [09:15<00:00, 34.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss = 10.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [09:12<00:00, 34.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: loss = 9.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertClass()\n",
    "model.to(device)\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=5e-5)\n",
    "model = train(model, criterion, optimizer, num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "677f5b92-0d6a-4a38-884b-6f468a71bcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                | 0/16 [00:00<?, ?it/s]/tmp/ipykernel_87980/4092967388.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'target': torch.tensor(self.y[index])\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [02:57<00:00, 11.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 64.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [02:57<00:00, 11.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 65.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db07a62b-5aaa-4429-90ad-20735cdb9564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                | 0/16 [00:00<?, ?it/s]/tmp/ipykernel_87980/4092967388.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'target': torch.tensor(self.y[index])\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [02:57<00:00, 11.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 62.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [02:57<00:00, 11.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 66.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_new = DistilBertClass()\n",
    "evaluate(model_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2a42909-ec4f-45ad-992e-70de1dc25ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "output_model_file = '../models/pytorch_distilbert.bin'\n",
    "output_vocab_file = '../models/vocab_distilbert.bin'\n",
    "\n",
    "torch.save(model, output_model_file)\n",
    "tokenizer.save_vocabulary(output_vocab_file)\n",
    "\n",
    "print('Model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf6873e-adae-4eb8-95ac-439693356784",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
