{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ToQ3t0Ns3II0"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_KHo45ru1cY0",
    "outputId": "817c53e5-fec2-4769-fbab-44489ba63d4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/jinlynn/miniconda3/envs/torch/lib/python3.9/site-packages (4.34.1)\n",
      "Requirement already satisfied: filelock in /Users/jinlynn/miniconda3/envs/torch/lib/python3.9/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/jinlynn/miniconda3/envs/torch/lib/python3.9/site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/jinlynn/miniconda3/envs/torch/lib/python3.9/site-packages (from transformers) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jinlynn/miniconda3/envs/torch/lib/python3.9/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/jinlynn/miniconda3/envs/torch/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/jinlynn/miniconda3/envs/torch/lib/python3.9/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /Users/jinlynn/miniconda3/envs/torch/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /Users/jinlynn/miniconda3/envs/torch/lib/python3.9/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/jinlynn/miniconda3/envs/torch/lib/python3.9/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/jinlynn/miniconda3/envs/torch/lib/python3.9/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in /Users/jinlynn/miniconda3/envs/torch/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/jinlynn/miniconda3/envs/torch/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jinlynn/miniconda3/envs/torch/lib/python3.9/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jinlynn/miniconda3/envs/torch/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jinlynn/miniconda3/envs/torch/lib/python3.9/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jinlynn/miniconda3/envs/torch/lib/python3.9/site-packages (from requests->transformers) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "LhawLhNC1uiy"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from transformers import BertTokenizer, BertTokenizerFast, BertForSequenceClassification\n",
    "from torch.optim import Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZV3h2ZST1fN0"
   },
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4sukAbeL1z_s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id    qid1    qid2                                          question1  \\\n",
      "0  133273  213221  213222  How is the life of a math student? Could you d...   \n",
      "1  402555  536040  536041                How do I control my horny emotions?   \n",
      "2  360472  364011  490273       What causes stool color to change to yellow?   \n",
      "3  150662  155721    7256                        What can one do after MBBS?   \n",
      "4  183004  279958  279959  Where can I find a power outlet for my laptop ...   \n",
      "\n",
      "                                           question2  is_duplicate  \n",
      "0  Which level of prepration is enough for the ex...             0  \n",
      "1                 How do you control your horniness?             1  \n",
      "2  What can cause stool to come out as little balls?             0  \n",
      "3                       What do i do after my MBBS ?             1  \n",
      "4  Would a second airport in Sydney, Australia be...             0  \n"
     ]
    }
   ],
   "source": [
    "train_full_df = pd.read_csv(\"quora data/train.tsv\", sep=\"\\t\")\n",
    "print(train_full_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KVEAtCWw16hT"
   },
   "outputs": [],
   "source": [
    "train_df, dev_df = train_test_split(train_full_df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(327461, 36385)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id    qid1    qid2  \\\n",
      "80519    51432   91228   91229   \n",
      "349125   52249   92541   92542   \n",
      "126605  135176  215925  215926   \n",
      "6008    184003  281230  281231   \n",
      "292788    5971   11714   11715   \n",
      "\n",
      "                                                question1  \\\n",
      "80519          Which topic is the most followed in Quora?   \n",
      "349125  What does it feel like to have sex with a rela...   \n",
      "126605                     Can I get back my best friend?   \n",
      "6008    Are there solar systems that act like a double...   \n",
      "292788                    Why are there only few magnets?   \n",
      "\n",
      "                                                question2  is_duplicate  \n",
      "80519         What topic on Quora has the most followers?             1  \n",
      "349125         Is it possible to eat more than you weigh?             0  \n",
      "126605   How do I get back to my best friend as my lover?             0  \n",
      "6008    As a Navy SEAL do you feel as if people are af...             0  \n",
      "292788                     Why is there only few magnets?             1  \n"
     ]
    }
   ],
   "source": [
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id    qid1    qid2                                          question1  \\\n",
      "0  201359  303345  303346            Why are African-Americans so beautiful?   \n",
      "1  263843   69383  380476  I want to pursue PhD in Computer Science about...   \n",
      "2  172974  266948  175089      Is there a reason why we should travel alone?   \n",
      "3   15329   29298   29299  Why are people so obsessed with having a girlf...   \n",
      "4  209794  314169  314170  What are some good baby girl names starting wi...   \n",
      "\n",
      "                                           question2  is_duplicate  \n",
      "0                    Why are hispanics so beautiful?             0  \n",
      "1  I handle social media for a non-profit. Should...             0  \n",
      "2             What are some reasons to travel alone?             1  \n",
      "3                How can a single male have a child?             0  \n",
      "4  What are some good baby girl names starting wi...             0  \n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"quora data/dev.tsv\", sep=\"\\t\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40430, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "n9i2MZqW1-8Q"
   },
   "outputs": [],
   "source": [
    "train_sentences1 = train_df['question1'].tolist()\n",
    "train_sentences2 = train_df['question2'].tolist()\n",
    "train_labels = train_df['is_duplicate'].tolist()\n",
    "\n",
    "dev_sentences1 = dev_df['question1'].tolist()\n",
    "dev_sentences2 = dev_df['question2'].tolist()\n",
    "dev_labels = dev_df['is_duplicate'].tolist()\n",
    "\n",
    "test_sentences1 = test_df['question1'].tolist()\n",
    "test_sentences2 = test_df['question2'].tolist()\n",
    "test_labels = test_df['is_duplicate'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "yJXYNmMz2BsD"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "train_encodings = tokenizer(train_sentences1, train_sentences2, truncation=True, padding=True)\n",
    "dev_encodings = tokenizer(dev_sentences1, dev_sentences2, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_sentences1, test_sentences2, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "CtkvGVG82GPK"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "TQ7vcopg2K4b"
   },
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_encodings, train_labels)\n",
    "dev_dataset = CustomDataset(dev_encodings, dev_labels)\n",
    "test_dataset = CustomDataset(test_encodings, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TXrH1AsZ2MeF"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 908,
     "referenced_widgets": [
      "551a90f364fd4faa85f55a7acd1327cb",
      "36864a46aed74b1bbeb0c9b7558a9a27",
      "571ef5ea83bd40399fba6e659bbe2217",
      "bf9486dc574842ed81ac1a8739080ff4",
      "384a0ac8598443e4908bfb3522e837b2",
      "3a6d98e01ae841219f62e1d51678bc23",
      "7643f8b25fa8490784dff4e9cb9ff7e8",
      "2ff673b8301c4dc6943eaa556e50d72e",
      "187b08c801824764afcb78218c66f688",
      "f8eefd7b3b8f481d8c4fea453363616a",
      "0ebbaad28e774325a1cd6d2a84f06906"
     ]
    },
    "id": "N3vK9zwB2QL2",
    "outputId": "0c93c976-238f-4869-d0c8-8971b2188752"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "optimizer = Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_built() \\\n",
    "    else \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model.to(device)\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mm_jZnvq2RAc"
   },
   "source": [
    "# Train, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "rXZPalB82TB0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch no: 1/3\n",
      "training epoch no: 2/3\n",
      "training epoch no: 3/3\n",
      "Train Accuracy: 0.910253943726632\n",
      "training time elapsed: 40 hours 47 minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "num_epochs = 3\n",
    "correct_train=0\n",
    "total_train=0\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"training epoch no: {epoch+1}/{num_epochs}\")\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, predicted = torch.max(outputs.logits, dim=1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "file_path = \"trained model.pkl\"\n",
    "torch.save(model.state_dict(), file_path)\n",
    "\n",
    "accuracy_train = correct_train/total_train\n",
    "print(f'Train Accuracy: {accuracy_train}')\n",
    "\n",
    "time_elapsed = time.time()-start_time\n",
    "hours = int(time_elapsed // 3600)\n",
    "minutes = int((time_elapsed % 3600) // 60)\n",
    "print(f\"training time elapsed: {hours} hours {minutes} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"trained model.pkl\")\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CnS_aHen2US_",
    "outputId": "c2c02ea3-57f4-4490-949f-41095e63e733"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 90.36%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92     23067\n",
      "           1       0.84      0.91      0.87     13318\n",
      "\n",
      "    accuracy                           0.90     36385\n",
      "   macro avg       0.89      0.90      0.90     36385\n",
      "weighted avg       0.91      0.90      0.90     36385\n",
      "\n",
      "validation time elapsed: 0 hours 20 minutes\n"
     ]
    }
   ],
   "source": [
    "# validation\n",
    "start_time = time.time()\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    true_y = []\n",
    "    predicted_combined = []\n",
    "    for batch in dev_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels']\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        _, predicted = torch.max(outputs.logits, dim=1)\n",
    "        true_y.extend(labels.numpy())\n",
    "        predicted_combined.extend(predicted.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(true_y, predicted_combined)\n",
    "print(f'Validation Accuracy: {accuracy*100:.2f}%')\n",
    "print(classification_report(true_y, predicted_combined))\n",
    "\n",
    "time_elapsed = time.time()-start_time\n",
    "hours = int(time_elapsed // 3600)\n",
    "minutes = int((time_elapsed % 3600) // 60)\n",
    "print(f\"validation time elapsed: {hours} hours {minutes} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 90.13%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92     25545\n",
      "           1       0.84      0.90      0.87     14885\n",
      "\n",
      "    accuracy                           0.90     40430\n",
      "   macro avg       0.89      0.90      0.90     40430\n",
      "weighted avg       0.90      0.90      0.90     40430\n",
      "\n",
      "Test time elapsed: 0 hours 14 minutes\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "start_time = time.time()\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    true_y = []\n",
    "    predicted_combined = []\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels']\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        _, predicted = torch.max(outputs.logits, dim=1)\n",
    "        true_y.extend(labels.numpy())\n",
    "        predicted_combined.extend(predicted.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(true_y, predicted_combined)\n",
    "print(f'Test Accuracy: {accuracy*100:.2f}%')\n",
    "print(classification_report(true_y, predicted_combined))\n",
    "\n",
    "time_elapsed = time.time()-start_time\n",
    "hours = int(time_elapsed // 3600)\n",
    "minutes = int((time_elapsed % 3600) // 60)\n",
    "print(f\"Test time elapsed: {hours} hours {minutes} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mm_jZnvq2RAc"
   },
   "source": [
    "# Without fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "optimizer = Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_built() \\\n",
    "    else \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model.to(device)\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CnS_aHen2US_",
    "outputId": "c2c02ea3-57f4-4490-949f-41095e63e733"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 51.25%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.40      0.51     23067\n",
      "           1       0.40      0.70      0.51     13318\n",
      "\n",
      "    accuracy                           0.51     36385\n",
      "   macro avg       0.55      0.55      0.51     36385\n",
      "weighted avg       0.59      0.51      0.51     36385\n",
      "\n",
      "Validation time elapsed: 0 hours 21 minutes\n"
     ]
    }
   ],
   "source": [
    "# validation\n",
    "start_time = time.time()\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    true_y = []\n",
    "    predicted_combined = []\n",
    "    for batch in dev_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels']\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        _, predicted = torch.max(outputs.logits, dim=1)\n",
    "        true_y.extend(labels.numpy())\n",
    "        predicted_combined.extend(predicted.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(true_y, predicted_combined)\n",
    "print(f'Validation Accuracy: {accuracy*100:.2f}%')\n",
    "print(classification_report(true_y, predicted_combined))\n",
    "\n",
    "time_elapsed = time.time()-start_time\n",
    "hours = int(time_elapsed // 3600)\n",
    "minutes = int((time_elapsed % 3600) // 60)\n",
    "print(f\"Validation time elapsed: {hours} hours {minutes} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 51.13%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.40      0.51     25545\n",
      "           1       0.40      0.70      0.51     14885\n",
      "\n",
      "    accuracy                           0.51     40430\n",
      "   macro avg       0.55      0.55      0.51     40430\n",
      "weighted avg       0.59      0.51      0.51     40430\n",
      "\n",
      "Test time elapsed: 0 hours 14 minutes\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "start_time = time.time()\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    true_y = []\n",
    "    predicted_combined = []\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels']\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        _, predicted = torch.max(outputs.logits, dim=1)\n",
    "        true_y.extend(labels.numpy())\n",
    "        predicted_combined.extend(predicted.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(true_y, predicted_combined)\n",
    "print(f'Test Accuracy: {accuracy*100:.2f}%')\n",
    "print(classification_report(true_y, predicted_combined))\n",
    "\n",
    "time_elapsed = time.time()-start_time\n",
    "hours = int(time_elapsed // 3600)\n",
    "minutes = int((time_elapsed % 3600) // 60)\n",
    "print(f\"Test time elapsed: {hours} hours {minutes} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0ebbaad28e774325a1cd6d2a84f06906": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "187b08c801824764afcb78218c66f688": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2ff673b8301c4dc6943eaa556e50d72e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36864a46aed74b1bbeb0c9b7558a9a27": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a6d98e01ae841219f62e1d51678bc23",
      "placeholder": "​",
      "style": "IPY_MODEL_7643f8b25fa8490784dff4e9cb9ff7e8",
      "value": "Downloading model.safetensors: 100%"
     }
    },
    "384a0ac8598443e4908bfb3522e837b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a6d98e01ae841219f62e1d51678bc23": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "551a90f364fd4faa85f55a7acd1327cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_36864a46aed74b1bbeb0c9b7558a9a27",
       "IPY_MODEL_571ef5ea83bd40399fba6e659bbe2217",
       "IPY_MODEL_bf9486dc574842ed81ac1a8739080ff4"
      ],
      "layout": "IPY_MODEL_384a0ac8598443e4908bfb3522e837b2"
     }
    },
    "571ef5ea83bd40399fba6e659bbe2217": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ff673b8301c4dc6943eaa556e50d72e",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_187b08c801824764afcb78218c66f688",
      "value": 440449768
     }
    },
    "7643f8b25fa8490784dff4e9cb9ff7e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf9486dc574842ed81ac1a8739080ff4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8eefd7b3b8f481d8c4fea453363616a",
      "placeholder": "​",
      "style": "IPY_MODEL_0ebbaad28e774325a1cd6d2a84f06906",
      "value": " 440M/440M [00:06&lt;00:00, 39.1MB/s]"
     }
    },
    "f8eefd7b3b8f481d8c4fea453363616a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
